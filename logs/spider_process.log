2025-03-24 21:19:04,722 - spider_process - ERROR - 运行爬虫时出错: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'
2025-03-24 21:19:04,724 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 101, in run_spider_process
    os.chdir(crawler_dir)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'

2025-03-24 21:26:06,712 - spider_process - ERROR - 运行爬虫时出错: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'
2025-03-24 21:26:06,714 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 101, in run_spider_process
    os.chdir(crawler_dir)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'

2025-03-24 21:28:02,354 - spider_process - ERROR - 运行爬虫时出错: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'
2025-03-24 21:28:02,354 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 101, in run_spider_process
    os.chdir(crawler_dir)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'

2025-03-24 21:30:42,439 - spider_process - ERROR - 运行爬虫时出错: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'
2025-03-24 21:30:42,440 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 101, in run_spider_process
    os.chdir(crawler_dir)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\python_learn\\CollectIp\\ip_operator\\crawl_ip\\crawl_ip'

2025-03-24 21:34:23,384 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:23,385 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:24,573 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:24,577 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:24,824 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:24,824 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:25,863 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:25,866 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:26,260 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:26,260 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:27,332 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:27,335 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:27,761 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:27,763 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:28,946 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:28,949 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:29,357 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:29,361 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:30,547 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:30,550 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:31,006 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:31,008 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:32,229 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:32,232 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:32,733 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:32,733 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:33,892 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:33,895 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:34,388 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:34,388 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:35,559 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:35,562 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:36,043 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:36,043 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:37,192 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:37,195 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:37,723 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:37,723 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:38,992 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:38,995 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:39,653 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:39,654 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:40,869 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:40,871 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:41,445 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:41,446 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:42,714 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:42,716 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:43,251 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:43,252 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:44,453 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:44,456 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:45,107 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:45,107 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:46,294 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:46,297 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:46,903 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:46,903 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:48,237 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:48,240 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:48,866 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:48,867 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:50,138 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:50,140 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:50,719 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:50,719 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:51,978 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:51,981 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:52,592 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:52,593 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:53,809 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:53,811 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:54,368 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:54,369 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:55,600 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:55,602 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:56,225 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:56,226 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:57,472 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:57,475 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:34:58,100 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:58,100 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:34:59,319 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:34:59,321 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:00,001 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:00,002 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:01,300 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:01,303 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:01,974 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:01,976 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:03,255 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:03,257 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:03,939 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:03,940 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:05,246 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:05,250 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:05,979 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:05,979 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:07,266 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:07,269 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:07,977 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:07,978 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:09,278 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:09,281 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:10,043 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:10,043 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:11,549 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:11,552 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:12,328 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:12,337 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:13,930 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:13,934 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:14,578 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:14,578 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:16,504 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:16,509 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:17,356 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:17,357 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:19,005 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:19,008 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:19,743 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:19,744 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:21,407 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:21,410 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:22,023 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:22,023 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:23,712 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:23,715 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:24,374 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:24,374 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:26,111 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:26,114 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:26,643 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:26,643 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:28,405 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:28,408 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:28,997 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:28,998 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:30,713 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:30,716 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:31,325 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:31,326 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:33,021 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:33,023 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:33,632 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:33,632 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:37,714 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:37,717 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:45,810 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:45,811 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:46,855 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:46,859 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:47,202 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:47,203 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:48,261 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:48,263 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:48,623 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:48,624 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:49,737 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:49,740 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:50,112 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:50,113 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:51,191 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:51,193 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:51,559 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:51,560 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:52,619 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:52,622 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:53,034 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:53,034 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:54,101 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:54,104 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:54,508 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:54,509 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:55,602 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:55,605 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:56,061 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:56,063 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:57,148 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:57,150 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:57,625 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:57,626 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:58,755 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:35:58,757 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:35:59,243 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:35:59,244 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:00,396 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:00,398 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:00,913 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:00,913 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:02,023 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:02,025 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:02,516 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:02,517 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:03,637 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:03,639 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:04,134 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:04,135 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:05,307 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:05,310 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:05,835 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:05,836 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:06,980 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:06,982 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:07,529 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:07,530 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:08,695 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:08,697 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:09,277 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:09,278 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:10,467 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:10,470 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:11,059 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:11,060 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:12,245 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:12,248 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:36:12,824 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:12,826 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:36:13,995 - spider_process - ERROR - 运行爬虫时出错: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)
2025-03-24 21:36:13,998 - spider_process - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 49, in <module>
    from crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 137, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 52, in <module>
    from ip_operator.crawl_ip.crawl_ip.crawl_ip.items import IndexIpItem, IpItem
ImportError: cannot import name 'IndexIpItem' from 'ip_operator.crawl_ip.crawl_ip.crawl_ip.items' (D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\items.py)

2025-03-24 21:38:08,772 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:08,773 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:09,796 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:09,797 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:10,031 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:10,032 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:11,078 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:11,078 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:11,313 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:11,314 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:12,467 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:12,467 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:12,731 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:12,732 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:14,244 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:14,245 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:14,571 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:14,572 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:15,820 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:15,821 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:16,113 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:16,114 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:17,394 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:17,395 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:17,704 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:17,704 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:19,284 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:19,286 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:19,657 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:19,658 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:21,040 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:21,041 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:21,414 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:21,416 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:22,841 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:22,842 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:23,352 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:23,353 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:24,829 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:24,830 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:25,237 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:25,238 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:26,610 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:26,613 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:27,037 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:27,038 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:28,448 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:28,448 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:28,949 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:28,952 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:30,450 - spider_process - INFO - 成功导入模块: crawl_ip.spiders.collectip
2025-03-24 21:38:30,450 - spider_process - INFO - 启动爬虫: collectip
2025-03-24 21:38:30,944 - spider_process - INFO - 尝试切换到目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:30,945 - spider_process - INFO - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-24 21:38:31,208 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:31,208 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:31,208 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:31,268 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:32,190 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:32,206 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:32,220 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:32,220 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:34,173 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:51,163 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:52,239 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:38:55,886 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:39:08,026 - spider_process - INFO - 爬虫 collectip 已完成运行
2025-03-24 21:49:40,518 - ERROR - 运行爬虫时出错: DLL load failed while importing cv2: 页面文件太小，无法完成操作。
2025-03-24 21:50:13,701 - ERROR - 运行爬虫时出错: DLL load failed while importing cv2: 页面文件太小，无法完成操作。
2025-03-24 22:35:22,020 - ERROR - 无法导入爬虫模块: douban
2025-03-24 22:35:57,272 - ERROR - 运行爬虫时出错: 'Logger' object has no attribute 'update_settings'
2025-03-25 16:03:21,585 - ERROR - 运行爬虫时出错: 'Logger' object has no attribute 'update_settings'
2025-03-25 16:03:55,953 - ERROR - 运行爬虫时出错: 'Logger' object has no attribute 'update_settings'
2025-03-25 16:05:43,337 - ERROR - 运行爬虫时出错: 'Logger' object has no attribute 'update_settings'
2025-03-25 16:13:00,986 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 16:13:02,152 - WARNING - 尝试导入 crawl_ip.spiders.douban 失败: No module named 'crawl_ip.spiders.douban'
2025-03-25 16:13:02,152 - WARNING - 尝试导入 crawl_ip.crawl_ip.spiders.douban 失败: No module named 'crawl_ip.crawl_ip'
2025-03-25 16:13:02,154 - WARNING - 尝试导入 ip_operator.crawl_ip.crawl_ip.crawl_ip.spiders.douban 失败: No module named 'ip_operator.crawl_ip.crawl_ip.crawl_ip.spiders.douban'
2025-03-25 16:13:02,155 - ERROR - 无法导入爬虫模块: douban
2025-03-25 16:29:56,403 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 16:29:57,652 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 16:58:32,662 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 16:58:34,033 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 19:03:39,907 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:03:41,373 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 19:04:24,471 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:04:25,715 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 19:06:14,167 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:15,544 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:15,889 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:17,222 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:17,555 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:19,378 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:19,962 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:22,240 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:22,974 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:25,387 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:26,014 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:28,484 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:29,208 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:31,584 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:32,763 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:35,705 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:36,556 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:39,389 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:40,298 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:42,936 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:43,853 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:46,034 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:46,898 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:49,784 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:51,169 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:53,862 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:54,920 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:06:58,271 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:06:59,491 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:02,409 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:03,727 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:06,117 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:07,513 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:10,222 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:11,808 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:14,967 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:16,279 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:19,152 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:20,080 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:22,243 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:23,262 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:25,895 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:27,091 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:29,503 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:07:30,632 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:07:34,747 - ERROR - 运行爬虫时出错: 
2025-03-25 19:07:34,767 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\collectip.py", line 15, in <module>
    from ddddocr import DdddOcr
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\ddddocr\__init__.py", line 10, in <module>
    import onnxruntime
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\onnxruntime\__init__.py", line 61, in <module>
    raise import_capi_exception
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\onnxruntime\__init__.py", line 24, in <module>
    from onnxruntime.capi._pybind_state import (
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\onnxruntime\capi\_pybind_state.py", line 32, in <module>
    from .onnxruntime_pybind11_state import *  # noqa
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ImportError

2025-03-25 19:18:45,054 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:18:49,517 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:18:49,775 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:18:53,922 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:18:54,346 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:18:59,111 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:18:59,664 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:04,591 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:05,161 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:10,871 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:11,576 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:17,091 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:17,836 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:24,707 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:25,545 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:30,301 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:31,004 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:19:36,651 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:19:37,498 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:33,932 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:37,153 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:21:37,713 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:41,568 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:21:42,307 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:46,401 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:21:47,219 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:51,238 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:21:52,042 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:21:57,654 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:21:58,918 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:06,531 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:07,519 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:14,119 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:14,940 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:19,720 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:20,642 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:25,118 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:26,125 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:31,998 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:33,016 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:38,972 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:39,949 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:46,037 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:47,697 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:22:53,926 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:22:54,767 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:00,263 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:01,316 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:06,944 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:07,938 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:13,073 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:14,019 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:19,042 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:19,998 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:24,280 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:26,106 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:32,021 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:33,222 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:38,694 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:39,734 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:45,429 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:46,765 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:51,665 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:23:52,682 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:23:57,257 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:22,335 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:25,826 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:26,180 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:30,193 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:30,729 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:35,481 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:36,058 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:41,841 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:42,590 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:48,409 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:49,059 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:53,810 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:32:54,445 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:32:59,262 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:33:00,106 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:33:05,191 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:33:06,015 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:33:12,607 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:33:13,359 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:33:22,471 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:33:23,517 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:33:29,027 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:33:29,832 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:41:24,629 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:41:26,025 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-25 19:51:12,067 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 19:51:14,216 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 22:12:46,960 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 22:12:48,220 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-25 22:13:45,321 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-25 22:13:46,632 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 19:52:44,249 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 19:52:45,773 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 20:35:07,538 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 20:35:09,154 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 20:44:32,397 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 20:44:35,975 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 20:46:06,837 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 20:46:08,141 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 20:55:44,377 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 20:55:45,802 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 21:31:01,959 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 21:31:03,562 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-26 22:43:58,864 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-26 22:44:00,425 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-27 09:10:53,689 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 09:10:55,204 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-27 09:23:35,355 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 09:23:36,733 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-27 10:17:53,383 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 10:17:54,833 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-27 20:05:19,259 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 20:05:20,497 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 130)
2025-03-27 20:05:20,501 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 130
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-27 20:20:04,276 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 20:20:05,544 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 130)
2025-03-27 20:20:05,547 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 130
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-27 20:21:45,935 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 20:21:47,307 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 130)
2025-03-27 20:21:47,312 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 130
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-27 20:22:17,115 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 20:22:18,279 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 130)
2025-03-27 20:22:18,281 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 130
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-27 20:27:27,600 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 20:27:29,049 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-27 21:08:37,672 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 21:08:38,817 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 130)
2025-03-27 21:08:38,820 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 130
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-27 21:16:52,110 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 21:16:53,475 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-27 21:21:36,647 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 21:21:37,877 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-27 22:59:08,990 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 22:59:10,466 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-27 23:04:16,405 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-27 23:04:17,636 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-28 15:11:10,589 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-28 15:11:11,914 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-28 15:12:47,544 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-28 15:12:48,653 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-28 23:42:12,384 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-28 23:42:13,739 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 146)
2025-03-28 23:42:13,742 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 146
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-29 12:22:58,273 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 12:22:59,659 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 146)
2025-03-29 12:22:59,662 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 146
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-29 12:28:27,390 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 12:28:28,669 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 146)
2025-03-29 12:28:28,671 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 146
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-29 12:47:58,712 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 12:48:00,126 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-29 13:45:37,817 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 13:45:38,992 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-29 13:54:13,194 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 13:54:14,361 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-29 15:21:24,497 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 15:21:25,925 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-29 15:47:25,340 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 15:47:26,773 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-29 15:54:08,062 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 15:54:09,477 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-29 16:35:07,070 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-29 16:35:08,398 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-30 22:56:29,486 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 22:56:30,885 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-30 22:59:13,211 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 22:59:14,607 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-30 23:00:02,122 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 23:00:03,307 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-30 23:00:45,805 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 23:00:47,375 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-30 23:24:04,530 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 23:24:05,969 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-30 23:34:26,612 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 23:34:28,079 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-30 23:39:46,605 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-30 23:39:47,798 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-31 16:15:13,361 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 16:15:14,846 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-31 16:21:31,062 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 16:21:32,556 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-31 16:34:28,650 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 16:34:29,965 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-03-31 16:35:48,806 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 16:35:50,007 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-31 16:41:37,324 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 16:41:38,791 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-03-31 17:06:01,260 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 17:06:02,847 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 519)
2025-03-31 17:06:02,851 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 519
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-31 22:47:19,265 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 22:47:20,793 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 519)
2025-03-31 22:47:20,796 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 519
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-31 22:49:04,770 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 22:49:05,868 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 519)
2025-03-31 22:49:05,871 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 519
    yield scrapy.Request(
IndentationError: unexpected indent

2025-03-31 23:02:52,977 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-03-31 23:02:54,149 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-04-01 20:51:27,364 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-01 20:51:29,190 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-04-02 22:02:36,363 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-02 22:02:37,761 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-04-03 15:25:17,672 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 15:25:18,997 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 519)
2025-04-03 15:25:19,001 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 519
    yield scrapy.Request(
IndentationError: unexpected indent

2025-04-03 15:30:45,041 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 15:30:46,131 - ERROR - 运行爬虫时出错: unexpected indent (douban_spider.py, line 519)
2025-04-03 15:30:46,132 - ERROR - Traceback (most recent call last):
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\services\crawler.py", line 135, in run_spider_process
    process = CrawlerProcess(settings)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\djangoLearn\Lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1206, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1074, in get_code
  File "<frozen importlib._bootstrap_external>", line 1004, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip\crawl_ip\spiders\douban_spider.py", line 519
    yield scrapy.Request(
IndentationError: unexpected indent

2025-04-03 16:08:19,980 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 16:08:19,980 - WARNING - 设置爬取配置: {'strategy': 'random_interval', 'max_interval': 3, 'max_pages': 5}
2025-04-03 16:08:21,345 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-04-03 16:08:21,346 - WARNING - 启动爬虫，参数: {'movie_name': '红高粱', 'comment_strategy': 'random_interval', 'max_pages': 5, 'max_interval': 3}
2025-04-03 16:40:04,993 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 16:40:04,993 - WARNING - 设置爬取配置: {'strategy': 'random_block', 'block_size': 6}
2025-04-03 16:40:06,330 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.douban_spider
2025-04-03 16:40:06,330 - WARNING - 启动爬虫，参数: {'movie_name': '红高粱', 'comment_strategy': 'random_block', 'block_size': 6}
2025-04-03 16:53:03,214 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 16:53:04,595 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-04-03 18:42:46,641 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 18:42:48,082 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-04-03 18:44:58,155 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 18:44:59,475 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-04-03 18:51:52,601 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 18:51:53,868 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-04-03 19:01:43,668 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 19:01:44,854 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
2025-04-03 19:19:15,209 - WARNING - 当前工作目录: D:\python_learn\CollectIp\CollectIp\ip_operator\crawl_ip\crawl_ip
2025-04-03 19:19:16,479 - WARNING - 成功导入爬虫模块: crawl_ip.spiders.collectip
